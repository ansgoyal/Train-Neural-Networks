{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Begin MNIST with CNN demo \n",
      "\n",
      "Creating 1000-item train Dataset from text file \n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": ".\\Data\\mnist_train_1000.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/Chestist/vsmsgtestcnn.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 178>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://codespaces%2Bansgoyal-chestist-wrrxvr464fwv7/workspaces/Chestist/vsmsgtestcnn.ipynb#ch0000001vscode-remote?line=175'>176</a>\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mEnd MNIST CNN demo \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://codespaces%2Bansgoyal-chestist-wrrxvr464fwv7/workspaces/Chestist/vsmsgtestcnn.ipynb#ch0000001vscode-remote?line=177'>178</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> <a href='vscode-notebook-cell://codespaces%2Bansgoyal-chestist-wrrxvr464fwv7/workspaces/Chestist/vsmsgtestcnn.ipynb#ch0000001vscode-remote?line=178'>179</a>\u001b[0m   main()\n",
      "\u001b[1;32m/workspaces/Chestist/vsmsgtestcnn.ipynb Cell 1'\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bansgoyal-chestist-wrrxvr464fwv7/workspaces/Chestist/vsmsgtestcnn.ipynb#ch0000001vscode-remote?line=92'>93</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mCreating 1000-item train Dataset from text file \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bansgoyal-chestist-wrrxvr464fwv7/workspaces/Chestist/vsmsgtestcnn.ipynb#ch0000001vscode-remote?line=93'>94</a>\u001b[0m train_file \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mData\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mmnist_train_1000.txt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bansgoyal-chestist-wrrxvr464fwv7/workspaces/Chestist/vsmsgtestcnn.ipynb#ch0000001vscode-remote?line=94'>95</a>\u001b[0m train_ds \u001b[39m=\u001b[39m MNIST_Dataset(train_file)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bansgoyal-chestist-wrrxvr464fwv7/workspaces/Chestist/vsmsgtestcnn.ipynb#ch0000001vscode-remote?line=96'>97</a>\u001b[0m bat_size \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bansgoyal-chestist-wrrxvr464fwv7/workspaces/Chestist/vsmsgtestcnn.ipynb#ch0000001vscode-remote?line=97'>98</a>\u001b[0m train_ldr \u001b[39m=\u001b[39m T\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(train_ds,\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bansgoyal-chestist-wrrxvr464fwv7/workspaces/Chestist/vsmsgtestcnn.ipynb#ch0000001vscode-remote?line=98'>99</a>\u001b[0m   batch_size\u001b[39m=\u001b[39mbat_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32m/workspaces/Chestist/vsmsgtestcnn.ipynb Cell 1'\u001b[0m in \u001b[0;36mMNIST_Dataset.__init__\u001b[0;34m(self, src_file)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bansgoyal-chestist-wrrxvr464fwv7/workspaces/Chestist/vsmsgtestcnn.ipynb#ch0000001vscode-remote?line=17'>18</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, src_file):\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bansgoyal-chestist-wrrxvr464fwv7/workspaces/Chestist/vsmsgtestcnn.ipynb#ch0000001vscode-remote?line=18'>19</a>\u001b[0m   all_xy \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mloadtxt(src_file, usecols\u001b[39m=\u001b[39;49m\u001b[39mrange\u001b[39;49m(\u001b[39m785\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bansgoyal-chestist-wrrxvr464fwv7/workspaces/Chestist/vsmsgtestcnn.ipynb#ch0000001vscode-remote?line=19'>20</a>\u001b[0m     delimiter\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39m\"\u001b[39;49m, comments\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m#\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat32)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bansgoyal-chestist-wrrxvr464fwv7/workspaces/Chestist/vsmsgtestcnn.ipynb#ch0000001vscode-remote?line=21'>22</a>\u001b[0m   tmp_x \u001b[39m=\u001b[39m all_xy[:, \u001b[39m0\u001b[39m:\u001b[39m784\u001b[39m]  \u001b[39m# all rows, cols [0,783]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bansgoyal-chestist-wrrxvr464fwv7/workspaces/Chestist/vsmsgtestcnn.ipynb#ch0000001vscode-remote?line=22'>23</a>\u001b[0m   tmp_x \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39m255\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/lib/npyio.py:1067\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     fname \u001b[39m=\u001b[39m os_fspath(fname)\n\u001b[1;32m   1066\u001b[0m \u001b[39mif\u001b[39;00m _is_string_like(fname):\n\u001b[0;32m-> 1067\u001b[0m     fh \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlib\u001b[39m.\u001b[39;49m_datasource\u001b[39m.\u001b[39;49mopen(fname, \u001b[39m'\u001b[39;49m\u001b[39mrt\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49mencoding)\n\u001b[1;32m   1068\u001b[0m     fencoding \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(fh, \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlatin1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1069\u001b[0m     fh \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(fh)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/lib/_datasource.py:193\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m \n\u001b[1;32m    190\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m ds \u001b[39m=\u001b[39m DataSource(destpath)\n\u001b[0;32m--> 193\u001b[0m \u001b[39mreturn\u001b[39;00m ds\u001b[39m.\u001b[39;49mopen(path, mode, encoding\u001b[39m=\u001b[39;49mencoding, newline\u001b[39m=\u001b[39;49mnewline)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/lib/_datasource.py:533\u001b[0m, in \u001b[0;36mDataSource.open\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[39mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[39m=\u001b[39mmode,\n\u001b[1;32m    531\u001b[0m                               encoding\u001b[39m=\u001b[39mencoding, newline\u001b[39m=\u001b[39mnewline)\n\u001b[1;32m    532\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 533\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m not found.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m path)\n",
      "\u001b[0;31mOSError\u001b[0m: .\\Data\\mnist_train_1000.txt not found."
     ]
    }
   ],
   "source": [
    "# mnist_cnn.py\n",
    "# PyTorch 1.10.0-CPU Anaconda3-2020.02  Python 3.7.6\n",
    "# Windows 10 \n",
    "\n",
    "# reads MNIST data from text file rather than using\n",
    "# built-in black box Dataset from torchvision\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as T\n",
    "\n",
    "device = T.device('cpu')\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "class MNIST_Dataset(T.utils.data.Dataset):\n",
    "  # 784 tab-delim pixel values (0-255) then label (0-9)\n",
    "  def __init__(self, src_file):\n",
    "    all_xy = np.loadtxt(src_file, usecols=range(785),\n",
    "      delimiter=\"\\t\", comments=\"#\", dtype=np.float32)\n",
    "\n",
    "    tmp_x = all_xy[:, 0:784]  # all rows, cols [0,783]\n",
    "    tmp_x /= 255\n",
    "    tmp_x = tmp_x.reshape(-1, 1, 28, 28)  # bs, chnls, 28x28\n",
    "    tmp_y = all_xy[:, 784]    # 1-D required\n",
    "\n",
    "    self.x_data = \\\n",
    "      T.tensor(tmp_x, dtype=T.float32).to(device)\n",
    "    self.y_data = \\\n",
    "      T.tensor(tmp_y, dtype=T.int64).to(device) \n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.x_data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    lbl = self.y_data[idx]  # no use labels\n",
    "    pixels = self.x_data[idx] \n",
    "    return (pixels, lbl)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "class Net(T.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()  # pre Python 3.3 syntax\n",
    "\n",
    "    self.conv1 = T.nn.Conv2d(1, 32, 5)  # chnl-in, out, krnl\n",
    "    self.conv2 = T.nn.Conv2d(32, 64, 5)\n",
    "    self.fc1 = T.nn.Linear(1024, 512)   # [64*4*4, x]\n",
    "    self.fc2 = T.nn.Linear(512, 256)\n",
    "    self.fc3 = T.nn.Linear(256, 10)     # 10 classes\n",
    "    self.pool1 = T.nn.MaxPool2d(2, stride=2) # kernel, stride\n",
    "    self.pool2 = T.nn.MaxPool2d(2, stride=2)\n",
    "    self.drop1 = T.nn.Dropout(0.25)\n",
    "    self.drop2 = T.nn.Dropout(0.50)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    # convolution phase         # x is [bs, 1, 28, 28]\n",
    "    z = T.relu(self.conv1(x))   # Size([bs, 32, 24, 24])\n",
    "    z = self.pool1(z)           # Size([bs, 32, 12, 12])\n",
    "    z = self.drop1(z)\n",
    "    z = T.relu(self.conv2(z))   # Size([bs, 64, 8, 8])\n",
    "    z = self.pool2(z)           # Size([bs, 64, 4, 4])\n",
    "   \n",
    "    # neural network phase\n",
    "    z = z.reshape(-1, 1024)     # Size([bs, 1024])\n",
    "    z = T.relu(self.fc1(z))     # Size([bs, 512])\n",
    "    z = self.drop2(z)\n",
    "    z = T.relu(self.fc2(z))     # Size([bs, 256])\n",
    "    z = self.fc3(z)             # Size([bs, 10])\n",
    "    return z\n",
    "\n",
    "def accuracy(model, ds):\n",
    "  ldr = T.utils.data.DataLoader(ds,\n",
    "    batch_size=len(ds), shuffle=False)\n",
    "  n_correct = 0\n",
    "  for data in ldr:\n",
    "    (pixels, labels) = data\n",
    "    with T.no_grad():\n",
    "      oupts = model(pixels)\n",
    "    (_, predicteds) = T.max(oupts, 1)\n",
    "    n_correct += (predicteds == labels).sum().item()\n",
    "\n",
    "  acc = (n_correct * 1.0) / len(ds)\n",
    "  return acc\n",
    "\n",
    "def main():\n",
    "  # 0. setup\n",
    "  print(\"\\nBegin MNIST with CNN demo \")\n",
    "  np.random.seed(1)\n",
    "  T.manual_seed(1)\n",
    "\n",
    "  # 1. create Dataset\n",
    "  print(\"\\nCreating 1000-item train Dataset from text file \")\n",
    "  train_file = \".\\\\Data\\\\mnist_train_1000.txt\"\n",
    "  train_ds = MNIST_Dataset(train_file)\n",
    "\n",
    "  bat_size = 10\n",
    "  train_ldr = T.utils.data.DataLoader(train_ds,\n",
    "    batch_size=bat_size, shuffle=True)\n",
    "\n",
    "  # 2. create network\n",
    "  print(\"\\nCreating CNN network with 2 conv and 3 linear \")\n",
    "  net = Net().to(device)\n",
    "\n",
    "  # 3. train model\n",
    "  max_epochs = 50  # 100 gives better results\n",
    "  ep_log_interval = 5\n",
    "  lrn_rate = 0.005\n",
    "  \n",
    "  loss_func = T.nn.CrossEntropyLoss()  # does log-softmax()\n",
    "  optimizer = T.optim.SGD(net.parameters(), lr=lrn_rate)\n",
    "  \n",
    "  print(\"\\nbat_size = %3d \" % bat_size)\n",
    "  print(\"loss = \" + str(loss_func))\n",
    "  print(\"optimizer = SGD\")\n",
    "  print(\"max_epochs = %3d \" % max_epochs)\n",
    "  print(\"lrn_rate = %0.3f \" % lrn_rate)\n",
    "\n",
    "  print(\"\\nStarting training\")\n",
    "  net.train()  # set mode\n",
    "  for epoch in range(0, max_epochs):\n",
    "    ep_loss = 0  # for one full epoch\n",
    "    for (batch_idx, batch) in enumerate(train_ldr):\n",
    "      (X, y) = batch  # X = pixels, y = target labels\n",
    "      optimizer.zero_grad()\n",
    "      oupt = net(X)\n",
    "      loss_val = loss_func(oupt, y)  # a tensor\n",
    "      ep_loss += loss_val.item()  # accumulate\n",
    "      loss_val.backward()  # compute grads\n",
    "      optimizer.step()     # update weights\n",
    "    if epoch % ep_log_interval == 0:\n",
    "      print(\"epoch = %4d   loss = %0.4f\" % (epoch, ep_loss))\n",
    "  print(\"Done \") \n",
    "\n",
    "  # 4. evaluate model accuracy\n",
    "  print(\"\\nComputing model accuracy\")\n",
    "  net.eval()\n",
    "  acc_train = accuracy(net, train_ds)  # all at once\n",
    "  print(\"Accuracy on training data = %0.4f\" % acc_train)\n",
    "\n",
    "  test_file = \".\\\\Data\\\\mnist_test_100.txt\"\n",
    "  test_ds = MNIST_Dataset(test_file)\n",
    "  net.eval()\n",
    "  acc_test = accuracy(net, test_ds)  # all at once\n",
    "  print(\"Accuracy on test data = %0.4f\" % acc_test)\n",
    "\n",
    "  # 5. make a prediction\n",
    "  print(\"\\nMaking prediction for fake image: \")\n",
    "  x = np.zeros(shape=(28,28), dtype=np.float32)\n",
    "  for row in range(5,23):\n",
    "    x[row][9] = 180  # vertical line\n",
    "  for rc in range(9,19):\n",
    "    x[rc][rc] = 250  # diagonal\n",
    "  for col in range(5,15):  \n",
    "    x[14][col] = 200  # horizontal\n",
    "  x /= 255.0\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(x, cmap=plt.get_cmap('gray_r'))\n",
    "  plt.show()\n",
    "\n",
    "  digits = ['zero', 'one', 'two', 'three', 'four', 'five', \n",
    "    'six', 'seven', 'eight', 'nine' ]\n",
    "  x = x.reshape(1, 1, 28, 28)  # 1 image, 1 channel\n",
    "  x = T.tensor(x, dtype=T.float32).to(device)\n",
    "  with T.no_grad():\n",
    "    oupt = net(x)  # 10 logits like [[-0.12, 1.03, . . ]]\n",
    "  am = T.argmax(oupt) # 0 to 9\n",
    "  print(\"\\nPredicted class is \\'\" + digits[am] + \"\\'\")\n",
    "\n",
    "  # 6. save model\n",
    "  print(\"\\nSaving trained model state\")\n",
    "  fn = \".\\\\Models\\\\mnist_model.pt\"\n",
    "  T.save(net.state_dict(), fn)  \n",
    "\n",
    "  print(\"\\nEnd MNIST CNN demo \")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
